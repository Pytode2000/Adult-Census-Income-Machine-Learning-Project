# Welcome to our Adult Census Income Repository!

## Contributors

Our group comprises three members: 
- [Gay Ming Kai](C230114@e.ntu.edu.sg) (@AuroraVane)
- [Jacob Ong Jia Chun](JONG163@e.ntu.edu.sg) (@Pytode)
- [Lim Zu Liang](E230184@e.ntu.edu.sg) (@Lzuliang)
  
We are from Tutorial Group: FCSA, Team: 1, and our teaching assistant is Mr. Girish Kumar Deepank.

## About
This is a mini-project for Nanyang Technology University's SC1015 Introduction to Data Science and Artificial Intelligence where students are grouped and tasked to select a dataset and complete the entire machine-learning pipeline.

Our team has chosen the Adult Census Income dataset (available at https://archive.ics.uci.edu/ml/datasets/Adult), which analyzes whether adults' incomes are above or below 50 thousand dollars based on a range of features.

For a detailed walkthrough, please peruse the [source code](main.ipynb) in the following order:
- Chapter 0. Library Setup
- Chapter 1. Dataset Overview
- Chapter 2. Problem Formulation & Motivations
- Chapter 3. Data Preparation
- Chapter 4. Exploratory Data Analysis
- Chapter 5: Feature Engineering
- Chapter 6. [Modelling](modelling.ipynb) (done on a separate notebook)
- Chapter 7. Conclusion

## Aim
Accurately predict whether an adult makes more than 50 thousand annually based on his/her attributes. 

## Models Used
1. BIRCH
2. Perceptron 
3. Random Forest
4. Decision Tree
5. Neural Network
6. Adaptive Boosting
7. Gradient Boosting
8. K-Means Clustering
9. Logistic Regression
10. K-Nearest Neighbours
11. Affinity Propagation
12. Gaussian Naive Bayes
13. Linear Support Vector
14. Bagging Classification
15. Support Vector Classifier
16. Stochastic Gradient Descent
17. Passive Aggressive Classifier

## Conclusion
- TBC

## What We Learnt & Explored
- Collaborating effectively using Github.
- Analysing possible options and making informed decisions.
- Intelligently locate and handle missing data.
- Explore various features' relations with the target.
- Utilise visualization to decide how to handle (engineer) features.
- Perform various Feature Engineering based on previous analysis and findings.
- Model comparison to select the best-performing algorithm.
- GridSearch to find optimal parameters for the best-performing algorithm.
- Feature Importance.
- Exporting and importing trained models to perform prediction. 

## References
- [1] https://www.data-to-viz.com/
- [2] https://archive.ics.uci.edu/dataset/2/adult
- [3] https://pbpython.com/categorical-encoding.html
- [4] https://www.mygreatlearning.com/blog/gridsearchcv/
- [5] https://www.geeksforgeeks.org/ml-gradient-boosting/
- [6] https://seaborn.pydata.org/tutorial/color_palettes.html
- [7] https://www.geeksforgeeks.org/what-is-feature-engineering/
- [8] https://www.geeksforgeeks.org/data-visualization-in-jupyter-notebook/
- [9] https://www.geeksforgeeks.org/data-visualization-with-python-seaborn/
- [10] https://towardsdatascience.com/jupyter-notebook-best-practices-f430a6ba8c69
- [11] https://towardsdatascience.com/data-preprocessing-with-python-pandas-part-5-binning-c5bd5fd1b950
- [12] https://www.ibm.com/docs/en/watson-studio-local/1.2.3?topic=notebooks-markdown-jupyter-cheatsheet
- [13] https://coderpad.io/blog/data-science/mastering-jupyter-notebooks-best-practices-for-data-science/
- [14] https://www.analyticsvidhya.com/blog/2021/05/dealing-with-missing-values-in-python-a-complete-guide/
- [15] https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/

