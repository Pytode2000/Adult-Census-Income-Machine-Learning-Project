{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b518e3-3187-4794-a96f-e47685a6922e",
   "metadata": {},
   "source": [
    "#### SC1015 FCSA Group 1: \n",
    "- Gay Ming Kai       (C230114@e.ntu.edu.sg)\n",
    "- Jacob Ong Jia Chun (JONG163@e.ntu.edu.sg)\n",
    "- Lim Zu Liang       (E230184@e.ntu.edu.sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e84890-e5c4-49c1-8193-7bc450820797",
   "metadata": {},
   "source": [
    "#### Nanyang Technology University, SC1015 Introduction to Data Science and Artificial Intelligence\n",
    "#### Tutorial: FCSA, Team: 1, Teaching Assistant: Mr. GIRISH KUMAR DEEPANK.\n",
    "#### Authors:\n",
    "- Gay Ming Kai (C230114@e.ntu.edu.sg)\n",
    "- Jacob Ong Jia Chun (JONG163@e.ntu.edu.sg)\n",
    "- Lim Zu Liang (E230184@e.ntu.edu.sg)\n",
    "\n",
    "Note: Please feel free to reach out to us should there be any queries or concerns!\n",
    "\n",
    "Brief Video Presentation (if the audio doubles on the first slide, go to the next slide then return): [Link](https://www.canva.com/design/DAGA3UcTBQc/QS1fChVqik4YSdmnALXurQ/edit?utm_content=DAGA3UcTBQc&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab6ba4c-1f27-413d-8446-ff2d588a5eef",
   "metadata": {},
   "source": [
    "<h1><center><u>Adult Census Income</u></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0d9f7-5db4-4667-b07b-a34348dbfafc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "### Flow of Notebook\n",
    "\n",
    "- Chapter 0. Library Setup\n",
    "\n",
    "- Chapter 1. Dataset Overview\n",
    "\n",
    "- Chapter 2. Problem Formulation & Motivations\n",
    "\n",
    "- Chapter 3. Data Preparation\n",
    "\n",
    "- Chapter 4. Exploratory Data Analysis\n",
    "\n",
    "- Chapter 5. Feature Engineering\n",
    "\n",
    "- Chapter 6. Modelling\n",
    "\n",
    "- Chapter 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fbd239-26fe-426a-95bc-a658afa57952",
   "metadata": {},
   "source": [
    "## Chapter 0. Library Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b1145-51be-4ae1-9c11-c394f141e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analysis and Wrangling Packages\n",
      "- pandas version: 2.0.3\n",
      "- NumPy version: 1.24.3\n",
      "- SciPy version: 1.11.1\n",
      "****************************************\n",
      "Visualization Packages\n"
     ]
    }
   ],
   "source": [
    "def separate():\n",
    "    print('*' * 40)\n",
    "\n",
    "print(\"Data Analysis and Wrangling Packages\")\n",
    "import pandas as pd # Library for data processing and analysis.\n",
    "import numpy as np # Library for numerical computing (provides support for multi-dimensional arrays and matrices).\n",
    "import scipy as sp # Library for scientific computing and advanced mathematics.\n",
    "print(\"- pandas version: {}\". format(pd.__version__))\n",
    "print(\"- NumPy version: {}\". format(np.__version__))\n",
    "print(\"- SciPy version: {}\". format(sp.__version__)) \n",
    "separate()\n",
    "print(\"Visualization Packages\")\n",
    "import matplotlib as plt # Plotting library.\n",
    "import seaborn as sns  # Statistical data visualization based on matplotlib.\n",
    "print(\"- matplotlib version: {}\".format(plt.__version__))\n",
    "print(\"- seaborn version: {}\".format(sns.__version__))\n",
    "separate()\n",
    "\n",
    "# Ignore depreciation warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Note: All modelling-realated packages are in a separate notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fe740f-45f3-47e7-95c2-73e43503f651",
   "metadata": {},
   "source": [
    "## Chapter 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7699eeb-7704-4614-97ba-b224b1ee9fcb",
   "metadata": {},
   "source": [
    "#### The dataset `(https://archive.ics.uci.edu/ml/datasets/Adult)` was donated by Ronny Kohavi and Barry Becker in 1994 and is currently managed by the University of California Irvine.\n",
    "\n",
    "The dataset has 1 target, 14 features, and 32561 instances, \n",
    "\n",
    "The 14 features are: \n",
    "- `age`\n",
    "- `workclass`\n",
    "- `fnlwgt`\n",
    "- `education`\n",
    "- `education-num`\n",
    "- `marital-status`\n",
    "- `occupation `\n",
    "- `relationship`\n",
    "- `race`\n",
    "- `sex`\n",
    "- `capital-gain`\n",
    "- `capital-loss`\n",
    "- `hours-per-week`\n",
    "- `native-country`\n",
    "\n",
    "The target is `income`.\n",
    "\n",
    "#### General Note:\n",
    "- Text-based values have an additional space in front (e.g., `sex` --> \" Male\").\n",
    "\n",
    "#### Data Preparation Note:\n",
    "- The dataset noted that there are missing values in 3 features: `workclass`, `occupation`, and `native-country`.\n",
    "- A thorough examination of all other features is still necessary for potential missing values.\n",
    "- After identifying the missing values, we will rectify them in Data Preparation.\n",
    "\n",
    "#### Exploratory Data Analysis Note:\n",
    "- The feature `fnlwgt`, short for \"Final Weight,\" denotes an estimated count of individuals represented by each row in the dataset. For instance, a given row might have `fnlwgt` = 2500, `age` = 50, `race` = \" White\", `sex` = \" Female\", indicating that approximately 2500 people share these characteristics. Given this interpretation, the `fnlwgt` feature is essentially a cardinal number representing group size and is logically independent of the target. To verify this assumption, we intend to conduct an analysis (in Exploratory Data Analysis) to assess whether `fnlwgt` influences the target or not.\n",
    "- The feature `education-num` seems to correspond to the numerical representation of the `education` feature. This means that each value in `education` is mapped to a corresponding numerical value in `education-num`. For instance, \"HS-grad\" in `education` might be represented as 9 in `education-num`. We will confirm this in Exploratory Data Analysis.  \n",
    "\n",
    "#### Feature Engineering Note:\n",
    "- If our analysis confirms that `fnlwgt` has no significant impact on the target, we will drop the feature.\n",
    "- \n",
    "Similarly, if our analysis confirm that `education-num` is derived from `education`,  indicating redundancy, we will remove one of the features during the Feature Engineering process. Given that machine learning models generally perform better with numerical data, we will choose to drop `education` over `education-num`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173eedb8-af07-44cb-97fb-f16550f8a7de",
   "metadata": {},
   "source": [
    "## Chapter 2. Problem Formulation & Motivations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7204caf7-023a-4164-a6f1-04ac239bbd52",
   "metadata": {},
   "source": [
    "The \"Adult\" dataset, although not as widely recognized, serves as a hidden gem ideal for beginners to venture into the realm of machine learning. Its age and lesser popularity notwithstanding, this dataset presents abundant opportunities for beginners like us to dive into fundamental aspects of machine learning, including Data Preparation, Exploratory Data Analysis, and Feature Engineering.\n",
    "\n",
    "The primary task of this dataset is to predict whether an individual's annual income exceeds $50,000 or not. This binary classification hinges on key features such as age, education level, occupation, marital status, and more. What makes this dataset particularly intriguing is its demand for thoughtful exploration and consideration of various options before narrowing down to the most logical choices which could be subjective so we will have to provide ample justification. This process not only enhances our machine-learning skills but also cultivates a deeper understanding of the nuances involved in predictive modeling.\n",
    "\n",
    "Technical aspects aside, exploring this dataset provides valuable insights into demographic attributes strongly correlated with higher income brackets, which will be immensely valuable as we prepare to enter the workforce in the coming years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc29db7-d42e-4fb8-b695-2ebf4cd539aa",
   "metadata": {},
   "source": [
    "## Chapter 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a683d7-fe90-4d74-ad30-9b9954fd1efc",
   "metadata": {},
   "source": [
    "### 3.1 Import Dataset as Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9167582b-9bc3-4d91-a931-88f5130af980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquiring data.\n",
    "\n",
    "# Reading a .data file (that does not have headers) into DataFrame.\n",
    "adult_data = pd.read_csv('data/adult.data', delimiter=\",\", header=None) \n",
    "\n",
    "# Since the dataset file does NOT provide the headers, we have to add them in ourselves.\n",
    "column_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \n",
    "                \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \n",
    "                \"hours-per-week\", \"native-country\", \"income\"]\n",
    "\n",
    "# Assign column names to DataFrame.\n",
    "adult_data.columns = column_names\n",
    "\n",
    "# Check & First look.\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1512be67-79b2-4acf-bcd3-4d089b28e2a9",
   "metadata": {},
   "source": [
    "### 3.2 Identify and Remove Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5543e-202d-4325-8237-df1ee5137149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for NULL (missing) values in the dataset.\n",
    "adult_data.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01140596-f000-440b-986e-4922bdeea31f",
   "metadata": {},
   "source": [
    "#### Findings:\n",
    "- Appears to not have any null/missing values, but Dataset Overview mentioned that missing values exists.\n",
    "- Missing values may be replaced with a representative value (e.g., \" MISSING\").\n",
    "\n",
    "#### Choices:\n",
    "- Option A: Peek at the data specifically to look for missing values.\n",
    "- Option B: Find all the possible values of the three features (categorical) that are said to have missing data.\n",
    "\n",
    "#### Perform:\n",
    "- Option B as it is more robust (merely peeking head and tail may not show us the missing data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d06152-c797-4c29-b028-e5aa9d31c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B.\n",
    "print(adult_data[\"workclass\"].value_counts())\n",
    "separate()\n",
    "print(adult_data[\"occupation\"].value_counts())\n",
    "separate()\n",
    "print(adult_data[\"native-country\"].value_counts())\n",
    "separate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da1b130-d635-41d3-8814-51998a6aaf08",
   "metadata": {},
   "source": [
    "#### Findings:\n",
    "- It seems that missing values are denoted as \" ?\".\n",
    "\n",
    "#### Perform\n",
    "- Check for the presence of missing values in all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487ff2fe-e2d4-43dc-8663-0ed003ce06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all presence and count of \" ?\" in the dataset.\n",
    "def check_missing():\n",
    "    print(\"Number of \\\" ?\\\" in:\\n\")\n",
    "    print(\"Column\", 11*' ', \"Count\")\n",
    "    print(\"-\"*25)\n",
    "    for i in adult_data.columns: \n",
    "        t = adult_data[i].value_counts() \n",
    "        index = list(t.index)\n",
    "        print(i, end=\"\")\n",
    "        # For styling purposes.\n",
    "        x = 20 - len(i) \n",
    "        for j in index:\n",
    "            temp = 0\n",
    "            if j == \" ?\":\n",
    "                # Once a '?' is found, print the number of '?' in the feature.\n",
    "                print (x * ' ', t[\" ?\"]) \n",
    "                temp = 1\n",
    "                break\n",
    "        if temp == 0:\n",
    "            # '?' is absent from all rows of a specific feature.\n",
    "            print (x * ' ', \"0\") \n",
    "    separate()\n",
    "    print(\"Row count: \", len(adult_data))\n",
    "    separate()\n",
    "check_missing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1419d9f-9510-4014-8d8a-4f74183bcfaa",
   "metadata": {},
   "source": [
    "#### Findings:\n",
    "- Just like what the dataset said, only `workclass`, `occupation`, and `native-country` contains missing data.\n",
    "- They are all categorical features (replacing with mean or median is not viable).\n",
    "\n",
    "#### Choices:\n",
    "- Option A: Remove rows containing missing data.<br>\n",
    "There are a maximum of 4262 missing data points (assuming no overlaps), which comprise about 13% of the total dataset.\n",
    "\n",
    "- Option B: Remove the columns that contain missing data (`workclass`, `occupation`, and `native-country`).<br>\n",
    "These three features are intuitively crucial and likely to significantly impact the target `income`.\n",
    " \n",
    "- Option C: Predict missing classification data based on other variables in the dataset using classification models like logistic regression.<br>\n",
    "Viable but can be inaccurate and time-consuming.\n",
    "  \n",
    "- Option D: Impute missing data using the respective features' mode.<br>\n",
    "It might skew the data and affect the model's prediction in later parts.\n",
    "\n",
    "#### Perform:\n",
    "- Option A. <br>Given that we have 14 features, even after removing the missing values, we would still have approximately 28 thousand data points, which is more than sufficient for reliable analysis and prediction. and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64b804-06f2-439f-9123-be983b6b6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A.\n",
    "adult_data = adult_data.drop(adult_data[\n",
    "                             (adult_data[\"workclass\"] == \" ?\") | \n",
    "                             (adult_data[\"occupation\"] == \" ?\") | \n",
    "                             (adult_data[\"native-country\"] == \" ?\")].index)\n",
    "\n",
    "# Check if successfully removed.\n",
    "check_missing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180e27a-44ff-4e47-84c3-60b7142c156b",
   "metadata": {},
   "source": [
    "### 3.3 Peeks and Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb531db-87bc-4a68-a282-39dc151df60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check features' datatypes.\n",
    "adult_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1b7af-22b8-4885-a9fc-1f30c4ec7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistical information of the numerical features. \n",
    "adult_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb441069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistical information of the catergorical features & target.\n",
    "adult_data[[\"workclass\",\"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"native-country\", \"income\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60227876-418f-4de8-afa7-5e5d5374cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek first 5 rows.\n",
    "adult_data.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e8427b-2005-4fd0-acd2-f3b91759d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek last 5 rows.\n",
    "adult_data.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88750c3-1d53-4e73-8c7d-3b94115ed476",
   "metadata": {},
   "source": [
    "#### Findings:\n",
    "- Features `age`, `education-num`, `fnlwgt`, `capital-gain`, `capital-loss`, `hours-per-week` are numerical.\n",
    "- Features `workclass`, `education`, `marital-status`, `occupation`, `relationship`, `race`, `native-country` are categorical.\n",
    "- Feature `sex` and target `income` are dichotomous/binary (also categorical).\n",
    "\n",
    "#### Feature Engineering Note:\n",
    "- Encode all categorical columns to numerical nominal values as machine learning algorithms work better with numerical values.\n",
    "- Feature `sex` and target `income` can be converted to binary (1 or 0).\n",
    "- Could potentially bin the numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a268c4",
   "metadata": {},
   "source": [
    "## Chapter 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0203efed",
   "metadata": {},
   "source": [
    "### Synopsis\n",
    "In EDA, we will be exploring the 14 features and the target. By exploring and analysing the data, we will do feature engineering upon the analysis to help with the training of our data for our various models.\n",
    "\n",
    "#### Plots Used\n",
    "- For the target `income` we will be using catergory plot which allow us to view the count of the income.\n",
    "- For numerical features we will first analyse the correlation using heatmap and then we will be using FacetGrid with distplot and a seperate displot to see the relationship between <=50K and 50k with the respective numerical feature through its shape. (<50k shape will be smaller than >=50k due to lesser sample size)\n",
    "- For catergorical features we will be using heatmap to see the relationship between <=50k and 50k with the respective catergorical feature by comparing the number of values to find notable data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4d6a8",
   "metadata": {},
   "source": [
    "### 4.1. Exploring the Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660424f-4c0b-4cde-8643-81482f689ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = 'income', data = adult_data, kind = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f4a43-ecf4-4abc-aa69-f6a6f25dba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of data in each Count catergory:\\n\")\n",
    "print(\"Income\", 11*' ', \"Instance\")\n",
    "print(\"-\"*25)\n",
    "adult_data_gb = adult_data.groupby('income')\n",
    "i = \"Income: <= 50k\"\n",
    "print(i, end=\"\")\n",
    "x = 20 - len(i) # For styling purposes\n",
    "print (x * ' ', adult_data_gb['income'].count().iloc[0])\n",
    "i = \"Income: > 50k\"\n",
    "print(i, end=\"\")\n",
    "x = 20 - len(i) # For styling purposes\n",
    "print (x * ' ', adult_data_gb['income'].count().iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d1fea7",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- Data is more concentrated towards <= 50k\n",
    "    - Lesser than equal to 50k: 22654\n",
    "    - More than 50k: 7508\n",
    "    \n",
    "#### Perform\n",
    "- Enumeration of target to 1 and 0 respectively for true binary classification and faster training time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bb1b45",
   "metadata": {},
   "source": [
    "### 4.2. Relationship Exploration with Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd79d626",
   "metadata": {},
   "source": [
    "#### 4.2.1. Correlation with Numerical Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f991fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping income to use correlation\n",
    "adult_data_corr = adult_data.copy()\n",
    "adult_data_corr[\"income\"] = adult_data_corr[\"income\"].map({\" <=50K\": 0, \" >50K\":1}) \n",
    "\n",
    "sns.heatmap(adult_data_corr[['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week','income']].corr(),\n",
    "           cmap = 'rocket',annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07b9dd",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "- `Income` being a classification/binary problem makes correlation a unreliable indicator of relevance\n",
    "- `fnlwgt` has the worst correlation with every variable at almost 0 and especially our target `income` despite the correlation reiablity issue\n",
    "- `education-num` has the best correlation\n",
    "- `capital-gain`, `hours-per-week` and `age` has 2nd best correlation\n",
    "- `capital-loss`, has the 3rd best correlation\n",
    "\n",
    "##### Perform\n",
    "- More analysis done on `fnlwgt` to decide if we need to drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682bf8b",
   "metadata": {},
   "source": [
    "#### 4.2.2. age vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2448749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(adult_data, col='income')\n",
    "g = g.map(sns.distplot, \"age\")\n",
    "sns.displot(data = adult_data,x='age',hue='income',kind='kde', fill=True,palette=sns.color_palette('bright')[:2], height=5, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c17c9",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "- We can see that majority of the density of data belongs to (20-35) <= 50k\n",
    "- <=50k data is positive skewed.\n",
    "- People with `age` between 20 and 70 seem to be more likely to have income >50k\n",
    "\n",
    "##### Perform\n",
    "- Binning can be used to analyse it much more easily in a heatmap with each group catergorised per 10 years of age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3863f5c5",
   "metadata": {},
   "source": [
    "#### 4.2.3. fnlwgt vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d7caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(adult_data, col='income')\n",
    "g = g.map(sns.distplot, \"fnlwgt\")\n",
    "sns.displot(data = adult_data,x='fnlwgt',hue='income',kind='kde', fill=True,palette=sns.color_palette('bright')[:2], height=5, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57b5e29",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "- The shape of <=50k and >50k is almost exactly the same\n",
    "- <=50k is the same as 50k just enlarged due to higher amount of data.\n",
    "\n",
    "##### Perform\n",
    "- With the displot and correlation evidence, its safe to say `fnlwgt` does not influence our target `income` and therefore we drop `fnlwgt` from dataframe to help speed up our training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df235e",
   "metadata": {},
   "source": [
    "#### 4.2.4. education-num vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(adult_data, col='income')\n",
    "g = g.map(sns.distplot, \"education-num\")\n",
    "sns.displot(data = adult_data,x='education-num',hue='income',kind='kde', fill=True,palette=sns.color_palette('bright')[:2], height=5, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d020450",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "- `education-num` below 8 seem to mostly be <=50k\n",
    "- `education-num` above 15 seen to mostly be >50k\n",
    "- Data felt more like a catergorical variable than a numerical variable\n",
    "\n",
    "##### Perform\n",
    "- Analysis with similar variable(`education`) to be compared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd656b",
   "metadata": {},
   "source": [
    "#### 4.2.5. capital-gain vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(adult_data, col='income')\n",
    "g = g.map(sns.distplot, \"capital-gain\")\n",
    "sns.displot(data = adult_data,x='capital-gain',hue='income',kind='kde', fill=True,palette=sns.color_palette('bright')[:2], height=5, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c88a579",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "- Income with >50k has more capital gain on average\n",
    "- 100000 capital-gain is a 100% gurantee for income >50k\n",
    "\n",
    "##### Perform\n",
    "- Binning would be required to analyse it much more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa638f",
   "metadata": {},
   "source": [
    "#### 4.2.6. capital-loss vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(adult_data, col='income')\n",
    "g = g.map(sns.distplot, \"capital-loss\")\n",
    "sns.displot(data = adult_data,x='capital-loss',hue='income',kind='kde', fill=True,palette=sns.color_palette('bright')[:2], height=5, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d84be72",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "- The data is spread out more evenly compared to `capital-gain` and it is more difficult to gather any observation from it\n",
    "- When capital-loss is between 1000 to 1500 there does not seem to be any >50k\n",
    "\n",
    "##### Perform\n",
    "- Binning would be required to analyse it much more easily in a heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe18bf6d",
   "metadata": {},
   "source": [
    "#### 4.2.7 hours-per-week vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(adult_data, col='income')\n",
    "g = g.map(sns.distplot, \"hours-per-week\")\n",
    "sns.displot(data = adult_data,x='hours-per-week',hue='income',kind='kde', fill=True,palette=sns.color_palette('bright')[:2], height=5, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1bbdd",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "- People with `hours-per-week` below 40 are generally from income group <=50k\n",
    "\n",
    "##### Perform\n",
    "- Binning would be required to analyse it much more easily in a heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cda9b9",
   "metadata": {},
   "source": [
    "#### 4.2.8. workclass vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de88a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.pyplot.figure(figsize=(10, 4))\n",
    "sns.heatmap(adult_data.groupby(['workclass', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True,fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"crest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc963c6",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- Without Pay is always below <= 50k as income is virtually 0\n",
    "- workclass is a good indicator as it is not distributed equally showing that workclass has weight in terms of determining income\n",
    "- Local-Gov, Federal-Gov, and State-Gov have similar spread and are under public sector and as such can be catergorised in the same group\n",
    "- Self-emp-inc is the only variable to skew towards >50k\n",
    "\n",
    "#### Perform\n",
    "- Encode `workclass` by combining local-gov, federal-gov and state-gov into public"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda9d46",
   "metadata": {},
   "source": [
    "#### 4.2.9. education vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881f7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.pyplot.figure(figsize=(10, 8))\n",
    "sns.heatmap(adult_data.groupby(['education', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"mako_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de401381",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- Bachelors is relatively evenly distributed\n",
    "- Prof-school, Masters and Doctorate skew towards > 50k\n",
    "- Pre-School, 1st to 12th grade school is skewed towards <=50k\n",
    "- assoc-acdm, assoc-voc and some college is relatively skewed towards <=50k\n",
    "\n",
    "#### Perform\n",
    "- Encode `education` into 3 different category as post-bachelor, pre-college, college"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b569527d",
   "metadata": {},
   "source": [
    "#### 4.2.10. marital-status vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.pyplot.figure(figsize=(10, 4))\n",
    "sns.heatmap(adult_data.groupby(['marital-status', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"flare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dabd346",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- Data is mostly skewed towards <= 50k for all values.\n",
    "- Married-civ-spouse is the most evenly distributed and taking up the frequently occured value.\n",
    "- Divorced, Never Married, Separated, Widowed & married-spouse-absent are very skewed towards <= 50k and can be catergorised together under single\n",
    "- Married-AF-spouse and Married-civ-spouse is evenly distributed and can be catergorised under married\n",
    "\n",
    "#### Perform\n",
    "- Encode `marital-status` by putting married-af-spouse and married-civ-spouse under married and the others as single"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adbeb51",
   "metadata": {},
   "source": [
    "#### 4.2.11. occupation vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3844023",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.pyplot.figure(figsize=(10, 8))\n",
    "sns.heatmap(adult_data.groupby(['occupation', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"magma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f76afdd",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- Data is mostly skewed towards <= 50k for all values.\n",
    "- Exec-Managerial and Prof-specialty is the most evenly distributed and takes up the frequently occurred value.\n",
    "- The values can be further grouped into the types they belong in for simplicity based on value analysis and real world knowledge of the catergorical type of jobs.\n",
    "\n",
    "#### Perform\n",
    "- Data will be encoded and binned under the following catergories\n",
    "    - \"Blue-Collar\" [from \" Craft-repair\", \" Machine-op-inspct\", \" Transport-moving\", \" Handlers-cleaners\", \" Farming-fishing\"]\n",
    "    - \"Support\" [from \" Adm-clerical\",\" Tech-support\"]\n",
    "    - \"Service\" [from \" Other-service\", \" Protective-serv\",\" Priv-house-serv\", \" Armed-Forces\"]\n",
    "    - \"Sales\" [from \" Sales\"]\n",
    "    - \"Professional\" [from \" Prof-specialty\",\" Exec-managerial\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2253d29",
   "metadata": {},
   "source": [
    "#### 4.2.12. relationship vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.pyplot.figure(figsize=(10, 4))\n",
    "sns.heatmap(adult_data.groupby(['relationship', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412e9d7",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- Data is mostly skewed towards <= 50k for all values however there are 2 values where the data is not skewed.\n",
    "- Husband and wife is the most evenly distributed with almost half of the values skewed towards >50k as such can be caterogrised together\n",
    "- The other variables can be catergorised together\n",
    "\n",
    "#### Perform\n",
    "- Encode `relationship` by catergorising husband and wife as married and other values as others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d3991",
   "metadata": {},
   "source": [
    "#### 4.2.13. race vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94140c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.pyplot.figure(figsize=(10, 4))\n",
    "sns.heatmap(adult_data.groupby(['race', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"cubehelix_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ca3b8",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- Data is mostly skewed towards <= 50k for all values. \n",
    "- For white where by majority of the > 50k belonging to white.\n",
    "\n",
    "#### Perform\n",
    "- Encode `race` where white is its own group and the other values are being encoded as others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e88c3",
   "metadata": {},
   "source": [
    "#### 4.2.14. sex vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a73733",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.pyplot.figure(figsize=(5, 2))\n",
    "sns.heatmap(adult_data.groupby(['sex', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"rocket_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e394f",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- Data is mostly skewed towards <= 50k for all values.\n",
    "- Only notable finding is male has a higher probability to be >50k over female.\n",
    "\n",
    "#### Perform\n",
    "- More EDA needs to be performed with multivariate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af1ff69",
   "metadata": {},
   "source": [
    "#### 4.2.15. native-country vs income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b854e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.pyplot.figure(figsize=(10, 20))\n",
    "sns.heatmap(adult_data.groupby(['native-country', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bad90",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- Data is mostly skewed towards <= 50k for all values\n",
    "- US contains the most amount of values\n",
    "- Taiwan/japan/iran where the data is the most evenly distributed.\n",
    "- Outlying-US where there are no data above >50k\n",
    "\n",
    "#### Perform\n",
    "- Encode `native-country` by putting US as its own value and other countries as others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d81979",
   "metadata": {},
   "source": [
    "### 4.3. Multivariable vs Income Relationship Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e3005",
   "metadata": {},
   "source": [
    "#### 4.3.1. Sex vs Occupation vs Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data_M = adult_data[adult_data[\"sex\"] == ' Male']\n",
    "adult_data_F = adult_data[adult_data[\"sex\"] == ' Female']\n",
    "f, axes = plt.pyplot.subplots(2, 1, figsize=(18, 18))\n",
    "sns.heatmap(adult_data_M.groupby(['occupation', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"vlag\",ax=axes[0]).set(title='Male')\n",
    "sns.heatmap(adult_data_F.groupby(['occupation', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"vlag\",ax=axes[1]).set(title='Female')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8191716",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "- Exec-Managerial, Prof-Speciality & Sales is different for male and female for spread of data of income\n",
    "- Might show that females in that field of work are generally not >50k and therefore has a weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5724d68d",
   "metadata": {},
   "source": [
    "#### 4.3.2. Sex vs Workclass vs Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.pyplot.subplots(2, 1, figsize=(18, 18))\n",
    "sns.heatmap(adult_data_M.groupby(['workclass', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"icefire\",ax=axes[0]).set(title='Male')\n",
    "sns.heatmap(adult_data_F.groupby(['workclass', 'income']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"icefire\",ax=axes[1]).set(title='Female')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82451f7",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "- The ratio of <= 50k : > 50k is much higher for most data when comparing male to female\n",
    "- This shows gender is a important variable as such would not need to be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0307b6",
   "metadata": {},
   "source": [
    "### 4.4. Miscellaneous Relationship Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8564e694",
   "metadata": {},
   "source": [
    "#### 4.4.1 education vs education-num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51304073",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.pyplot.figure(figsize=(18, 8))\n",
    "\n",
    "sns.heatmap(adult_data.groupby(['education', 'education-num']).size().unstack(fill_value=0), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"Spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce63a4",
   "metadata": {},
   "source": [
    "#### Findings\n",
    "- There are a total of 16 unique boxes with its count corresponding correctly to `education`, as such I can conclude `education-num` is the encoded version of `education`.\n",
    "- The encoded values are\n",
    "    - Preschool: 1\n",
    "    - 1st-4th: 2\n",
    "    - 5th-6th: 3\n",
    "    - 7th-8th: 4\n",
    "    - 9th: 5\n",
    "    - 10th: 6\n",
    "    - 11th: 7\n",
    "    - 12th: 8\n",
    "    - HS-Grad: 9\n",
    "    - Some-College: 10\n",
    "    - Assoc-voc: 11\n",
    "    - Assoc-acdm: 12\n",
    "    - Bachelors: 13\n",
    "    - Masters: 14\n",
    "    - Prof-school: 15\n",
    "    - Doctorate: 16\n",
    "\n",
    "#### Perform\n",
    "- Remove `education` in FE as we would be encoding all catergorical features to numeric catergory eventually\n",
    "- Encode `education-num` based on previous findings in `5.4.8. education vs income`\n",
    "- Encoding `education-num` can be done where by 1 to 9 is HS-And-Below, 10 to 12 as College, 13 to 16 as Bachelors and above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e28d0-e3a5-46dd-b297-78bc6cdcccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "things to minimally do in EDA:\n",
    "1. find out education-num is mapped education\n",
    "2. find out fnlwgt doesnt affect target (probs use corr or something).\n",
    "MORE but idk what yet.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0012ced5-b019-43cf-be80-cc56bd564880",
   "metadata": {},
   "source": [
    "## Chapter 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a86708-6aa2-451c-b825-bd0d64ccd665",
   "metadata": {},
   "source": [
    "### Synopsis\n",
    "Perform (based on notes collected in earlier chapters):\n",
    "- One-hot encode all categorical variables: </br>\n",
    "  `workclass`, `marital-status`,\n",
    "  `occupation`, `relationship`, `race`, `sex`, `native-country`, and `income`.\n",
    "- Drop `fnlwgt` and `education`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4180047e-c26a-4422-8735-47aa790c5479",
   "metadata": {},
   "source": [
    "### 5.1. Encode `workclass`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d24b26-28ce-4209-ad00-b0a8a20b7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the spread and all the possible values of the feature.\n",
    "adult_data[\"workclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769140e7-f194-456a-a427-11ddd1a59242",
   "metadata": {},
   "source": [
    "#### Judging from the spread, we can further group this feature to: \n",
    "- \"Private\" <br>[from \" Private\"]\n",
    "- \"Public\" <br>[from \" Local-gov\", \" State-gov\", \" Federal-gov\"]\n",
    "- \"Self-Employed\" <br>[from \" Self-emp-not-inc\", \" Self-emp-inc\"]\n",
    "- \"Others\" <br>[from \" Without-pay\"].\n",
    "\n",
    "#### Then, we can encode these to nominal numeric values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary.\n",
    "workclass_dict = {\n",
    "    \" Without-pay\": 0, \n",
    "    \" Private\": 1, \n",
    "    \" Self-emp-not-inc\": 2, \" Self-emp-inc\": 2, \n",
    "    \" Local-gov\": 3, \" State-gov\": 3, \" Federal-gov\" : 3\n",
    "}\n",
    "\n",
    "# Replace values using the mapping dictionary.\n",
    "adult_data[\"workclass\"] = adult_data[\"workclass\"].replace(workclass_dict)\n",
    "\n",
    "# Check.\n",
    "adult_data[\"workclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c426a-2202-45b9-a63b-f2bf7f712823",
   "metadata": {},
   "source": [
    "### 5.2. Encode `marital-status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681c6a15-134c-4442-b623-3d2643cc80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the spread and all the possible values of the feature.\n",
    "adult_data[\"marital-status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95564b5-1e62-4a22-80fc-a97dcd987ae6",
   "metadata": {},
   "source": [
    "#### Judging from the spread, we can further group this feature to: \n",
    "- \"Single\" <br>[from \" Never-married\", \" Divorced\", \" Separated\", \" Widowed\"]\n",
    "- \"Married\" <br>[from \" Married-civ-spouse\",\" Married-spouse-absent\",\" Married-AF-spouse\"]\n",
    "\n",
    "#### Then, we can encode \"Single\" to 0, and \"Married\" to 1 (nominal numeric values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary.\n",
    "marital_dict = {\n",
    "    \" Never-married\" : 0, \" Divorced\" : 0, \" Separated\" : 0, \" Widowed\" : 0,\n",
    "    \" Married-civ-spouse\" : 1,\" Married-spouse-absent\" : 1,\" Married-AF-spouse\" : 1\n",
    "}\n",
    "\n",
    "# Replace values using the mapping dictionary.\n",
    "adult_data[\"marital-status\"] = adult_data[\"marital-status\"].replace(marital_dict)\n",
    "\n",
    "# Check.\n",
    "adult_data[\"marital-status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2689a269-0ac7-4cf8-8e76-d64e4e5d8c70",
   "metadata": {},
   "source": [
    "### 5.3. Encode `occupation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed21da-27fa-4a43-a4d8-fad08f9ce839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the spread and all the possible values of the feature.\n",
    "adult_data[\"occupation\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13dc636-156e-406a-9d31-fb3974c7c8f6",
   "metadata": {},
   "source": [
    "#### Judging from the spread, we can further group this feature to:\n",
    "- \"Blue-Collar\" [from \" Craft-repair\", \" Machine-op-inspct\", \" Transport-moving\", \" Handlers-cleaners\", \" Farming-fishing\"]\n",
    "- \"Support\" [from \" Adm-clerical\",\" Tech-support\"]\n",
    "- \"Service\" [from \" Other-service\", \" Protective-serv\",\" Priv-house-serv\", \" Armed-Forces\"]\n",
    "- \"Sales\" [from \" Sales\"]\n",
    "- \"Professional\" [from \" Prof-specialty\",\" Exec-managerial\"]\n",
    "\n",
    "#### Then, we can encode these to nominal numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98831a-3d2f-4290-8e21-10aabce24e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary.\n",
    "occupation_dict = {\n",
    "    \" Craft-repair\" : 0, \" Machine-op-inspct\" : 0, \" Transport-moving\" : 0, \" Handlers-cleaners\" : 0, \" Farming-fishing\" : 0,\n",
    "    \" Adm-clerical\" : 1, \" Tech-support\" : 1,\n",
    "    \" Other-service\" : 2, \" Protective-serv\" : 2, \" Priv-house-serv\" : 2, \" Armed-Forces\" : 2, \n",
    "    \" Sales\" : 3, \n",
    "    \" Prof-specialty\" : 4, \" Exec-managerial\" : 4,\n",
    "}\n",
    "\n",
    "# Replace values using the mapping dictionary.\n",
    "adult_data[\"occupation\"] = adult_data[\"occupation\"].replace(occupation_dict)\n",
    "\n",
    "# Check.\n",
    "adult_data[\"occupation\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c58d1-7e22-4521-a6b5-9f5163880cc5",
   "metadata": {},
   "source": [
    "### 5.4. Encode `relationship`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52bb129-236b-4682-8733-8a0344877ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the spread and all the possible values of the feature.\n",
    "adult_data[\"relationship\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a9ccf8-d191-44a8-9692-6927e0316680",
   "metadata": {},
   "source": [
    "#### Judging from the spread, we can further group this feature to: \n",
    "- \"Married\" <br>[from \" Husband\",\" Wife\"]\n",
    "- \"Others\" <br>[from \" Not-in-family\", \" Own-child\", \" Unmarried\", \" Other-relative\"]\n",
    "\n",
    "#### Then, we can encode \"Married\" to 1, and \"Others\" to 1 (nominal numeric values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f90c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values.\n",
    "adult_data[\"relationship\"] = adult_data[\"relationship\"].apply(lambda x: 1 if \" Husband\" in x or \" Wife\" in x else 0)\n",
    "\n",
    "# Check.\n",
    "adult_data[\"relationship\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc37ee87-ca60-46ea-a6f6-f2e1085e2382",
   "metadata": {},
   "source": [
    "### 5.5. Encode `race`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b02c4-2e33-4a9a-a1b5-4314df2988bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the spread and all the possible values of the feature.\n",
    "adult_data[\"race\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76937be7-9627-4ed9-a3dc-41406d7ce4bd",
   "metadata": {},
   "source": [
    "#### Judging from the spread, we can further group this feature to: \n",
    "- \"White\" <br>[from \" White\"]\n",
    "- \"Others\" <br>[from \" Black\", \" Asian-Pac-Islander\", \" Amer-Indian-Eskimo\", \" Other\"]\n",
    "\n",
    "#### Then, we can encode \"White\" to 1, and \"Others\" to 0 (nominal numeric values).). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc50bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values.\n",
    "adult_data[\"race\"] = adult_data[\"race\"].apply(lambda x: 1 if \" White\" in x else 0)\n",
    "\n",
    "# Check.\n",
    "adult_data[\"race\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09987597-90bd-4b44-8bb0-abb2277ebce2",
   "metadata": {},
   "source": [
    "### 5.6. Encode `sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2fa797-5455-498a-a8ba-fbe960f86661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the spread and all the possible values of the feature.\n",
    "adult_data[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecacedd-3708-41fe-bdeb-615700f7b0a1",
   "metadata": {},
   "source": [
    "#### Simply map to nominal numeric values [\" Male\" = 0, \" Female\" = 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map values.\n",
    "adult_data[\"sex\"] = adult_data[\"sex\"].map({\" Male\": 0, \" Female\": 1}) \n",
    "\n",
    "# Check.\n",
    "adult_data[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64638fd9-5ea9-474c-919a-d94155b75c55",
   "metadata": {},
   "source": [
    "### 5.7. Encode `native-country`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5755d8-16b5-4cfb-b034-06694669fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the spread and all the possible values of the feature.\n",
    "adult_data[\"native-country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4883464a-7ab1-49bd-bb0d-949575c23ad6",
   "metadata": {},
   "source": [
    "#### Judging from the spread, we can further group this feature to: \n",
    "- \"US\" <br>[from \" United-States\"]\n",
    "- \"Others\" <br>[from all other values]\n",
    "\n",
    "#### Then, we can encode \"US\" to 1, and \"Others\" to 0 (nominal numeric values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef36eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values.\n",
    "adult_data[\"native-country\"] = adult_data[\"native-country\"].apply(lambda x: 1 if \" United-States\" in x else 0)\n",
    "\n",
    "# Check.\n",
    "adult_data[\"native-country\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c9cfa1",
   "metadata": {},
   "source": [
    "### 5.8. Encode `education-num`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary.\n",
    "education_num_dict = {\n",
    "    1 : 0, 2 : 0, 3 : 0, 4 : 0,\n",
    "    5 : 0, 6 : 0, 7 : 0, 8 : 0, 9 : 0, 10 : 1, 11 : 1, 12 : 1,13 : 2,14 : 2,15 : 2,16 : 2\n",
    "}\n",
    "\n",
    "# Replace values using the mapping dictionary.\n",
    "adult_data[\"education-num\"] = adult_data[\"education-num\"].replace(education_num_dict)\n",
    "\n",
    "# Check.\n",
    "adult_data[\"education-num\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c6c38-49b9-4640-817d-1ccafd0fcdf5",
   "metadata": {},
   "source": [
    "### 5.9. Encode `income`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c15d66-a3f8-4f26-822d-24c58b024eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the spread and all the possible values of the label.\n",
    "adult_data[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c530b2-f83a-42a6-8baa-ccd05333fbcc",
   "metadata": {},
   "source": [
    "#### Simply map to nominal numeric values [\" <=50K\" = 0, \" >50K\" = 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cce439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map values.\n",
    "adult_data[\"income\"] = adult_data[\"income\"].map({\" <=50K\": 0, \" >50K\":1}) \n",
    "\n",
    "# Check.\n",
    "adult_data[\"income\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cf8e67",
   "metadata": {},
   "source": [
    "### 5.10. Binning `age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7000e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin Values.\n",
    "bins = [0,20,30,40,50,60,70,100]\n",
    "lbs = [0,1,2,3,4,5,6]\n",
    "adult_data['age'] = pd.cut(adult_data['age'], bins,labels = lbs)\n",
    "\n",
    "# Check.\n",
    "adult_data[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9314aa68",
   "metadata": {},
   "source": [
    "### 5.11. Binning `capital-gain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83968790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin Values.\n",
    "bins = [-1,0,10000,20000,30000,50000,100000]\n",
    "lbs = [0,1,2,3,4,5]\n",
    "adult_data['capital-gain'] = pd.cut(adult_data['capital-gain'], bins,labels = lbs)\n",
    "\n",
    "# Check.\n",
    "adult_data[\"capital-gain\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5e763",
   "metadata": {},
   "source": [
    "### 5.12. Binning `capital-loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cBin Values.\n",
    "bins = [-1,0,1000,2000,3000,5000]\n",
    "lbs = [0,1,2,3,4]\n",
    "adult_data['capital-loss'] = pd.cut(adult_data['capital-loss'], bins,labels = lbs)\n",
    "\n",
    "# Check.\n",
    "adult_data[\"capital-loss\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663bb8a",
   "metadata": {},
   "source": [
    "### 5.13. Binning `hours-per-week`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin Values.\n",
    "bins = [0,20,30,40,50,60,70,100]\n",
    "lbs = [0,1,2,3,4,5,6]\n",
    "adult_data['hours-per-week'] = pd.cut(adult_data['hours-per-week'], bins,labels = lbs)\n",
    "\n",
    "# Check.\n",
    "adult_data[\"hours-per-week\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26164008-e069-43c6-a8e1-724aa25b0279",
   "metadata": {},
   "source": [
    "### 5.14. Drop `fnlwgt` & `education`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd32f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data = adult_data.drop(\n",
    "    [\"fnlwgt\", 'education'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2bcc4f-c848-421f-89bd-d302017ee5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final look at our refined dataset.\n",
    "adult_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d059a9f2-1bab-4f92-ac06-8cd260c4f2c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adult_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30a284-7f6e-4f63-aa87-08cd5c04cfbc",
   "metadata": {},
   "source": [
    "## Chapter 6. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1727a880-5600-45a6-b3bf-0773f8585f7e",
   "metadata": {},
   "source": [
    "#### Plan:\n",
    "We intend to train 17 different models using their default base parameters, and then optimize the best-performing model through hyperparameter tuning using GridSearch. While the best-performing base model doesn't guarantee the top-performing hyperparameterized model, this approach is chosen due to resource and time constraints. It is understood that hyperparameter tuning can be computationally intensive, so we will prioritize refining the most promising models to achieve improvements in model performance within the available resources.\n",
    "\n",
    "#### The 17 models chosen are:\n",
    "    1. BIRCH\n",
    "    2. Perceptron \n",
    "    3. Random Forest\n",
    "    4. Decision Tree\n",
    "    5. Neural Network\n",
    "    6. Adaptive Boosting\n",
    "    7. Gradient Boosting\n",
    "    8. K-Means Clustering\n",
    "    9. Logistic Regression\n",
    "    10. K-Nearest Neighbours\n",
    "    11. Affinity Propagation\n",
    "    12. Gaussian Naive Bayes\n",
    "    13. Linear Support Vector\n",
    "    14. Bagging Classification\n",
    "    15. Support Vector Classifier\n",
    "    16. Stochastic Gradient Descent\n",
    "    17. Passive Aggressive Classifier\n",
    "\n",
    "#### Perform:\n",
    "We will export the processed dataset and conduct modelling in a separate notebook due to its time-intensive nature (training 17 models followed by GridSearch). Other experiments and findings such as Feature Importance and Sample Prediction will all be done in the modelling notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5730e08f-34c5-4b6d-9d65-1deaf071a51e",
   "metadata": {},
   "source": [
    "### 6.1. Exporting Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6776fef-b04e-4fad-8cc4-1fc0f37bb5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrame to CSV.\n",
    "adult_data.to_csv(\"data/adult_processed.csv\", index=False)\n",
    "\n",
    "# Please proceed to the modelling notebook (modelling.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d784cb",
   "metadata": {},
   "source": [
    "### 6.2 Modelling Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cec97c",
   "metadata": {},
   "source": [
    "The best model is **Gradient Boosting** at an accuracy of **86%**\n",
    "\n",
    "The top 3 most important features are\n",
    "- relationship    - 41.69%\n",
    "- education_num   - 19.42%\n",
    "- capital-gain    - 12.11%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a015c7-3a86-4494-a81a-feb5d5d72934",
   "metadata": {},
   "source": [
    "## Chapter 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a0084",
   "metadata": {},
   "source": [
    "### Statistical Inference\n",
    "After conducting a comprehensive data cleaning and feature engineering process, we fitted our data to 17 diverse models, encompassing both classification (supervised) and clustering (unsupervised) techniques. Based on the evaluation, we can conclude that Gradient Boosting, a boosting algorithm used for classification tasks, emerged as the best-performing model with an accuracy of **86%**.\n",
    "\n",
    "We believe that the superior performance of the Gradient Boosting model is primarily due to its ability to combine several weaker learners, such as decision trees and linear models, into a strong ensemble. This model attempts to minimize the loss function, like Mean-Squared Error (MSE), using gradient descent [5], which is another technique we employed.\n",
    "\n",
    "As a result, this improved amalgamation of various models has proven its worth by outperforming the other models in our analysis. With an 86% accuracy, this model can effectively solve our problem of predicting whether a person's income is above or below 50k, given that at least the following features are provided: `relationship`, `education`, and `capital-gain`.\n",
    "\n",
    "### Ethical Considerations\n",
    "Using this trained model, we are able to gauge a person's income from our everyday conversation with the person, which is **not ethical** despite being **legal**. This is due to the fact that most people generally do not want others to know how much they make, due to either their pride or shame, with income being a common determiner of whether a person is successful.\n",
    "\n",
    "However, there is a caveat to that in the sense that when a person shares their job, education, or relationship status, you can technically be able to guess if a person is making a large income. This is due to the consensus that the higher the education, the more money one makes, and generally, people who have a spouse are more successful than those who are single.\n",
    "\n",
    "Therefore, I ultimately believe that this research is **not** crossing an ethical line.\n",
    "\n",
    "### Insights\n",
    "From this kernel, we have performed Exploratory Data Analysis and Feature Engineering. We have learned the importance of analyzing the data properly and removing irrelevant data to facilitate the training process for our various models. We also understand the importance of binning our variables. Initially, we performed the analysis without binning, and the training times were exponentially longer. This is due to the fact that computers take longer to process strings, as they must break them apart and analyze them based on ASCII characters, as opposed to enumerated integers, which are much easier for the model to process at the machine level.\n",
    "\n",
    "Furthermore, while training our 17 models, we have gained a better understanding of how the models function, as well as the reasons behind why each model gave good or poor accuracy. This knowledge will allow us to identify ways to improve the model performance.\n",
    "\n",
    "### Intelligent Decision & Future Possibilities\n",
    "#### Training Limitation\n",
    "Due to the limitations of our workspace, we are unable to fully utilize grid search to its highest potential. The training process puts a heavy toll on our CPU and RAM, resulting in our inability to perform other tasks. Furthermore, due to the climate in Singapore and the lack of a proper cooling system, the heat generated during training could potentially cause irreparable damage to our training rigs.\n",
    "\n",
    "After weighing the pros and cons, we have decided to limit the use of grid search to only our best-performing model.\n",
    "\n",
    "Additionally, we are also unable to utilize more advanced neural network models from TensorFlow and PyTorch, such as Convolutional Neural Networks (CNNs). This is because our GPUs lack the ability to host CUDA, which is only compatible with NVIDIA GPUs and not AMD GPUs. As a result, training CNNs would take an excessively long time, making it nearly impossible to meet our deadline.\n",
    "\n",
    "#### Dataset Limitation\n",
    "This model appears to be primarily fine-tuned for United States citizens, as evidenced by the fact that nearly **98%** of the `native-country` values belong to the United States. As a result, the model's reliability and accuracy may not be as good when used to predict data for individuals whose native country is not the United States. This is because the data is heavily skewed towards the United States, making it a poor indicator for other nationalities. Consequently, the importance percentage of this feature in our training is only **0.77%**.\n",
    "\n",
    "Given the opportunity to create a model for predicting adult census data and the resources to gather our own dataset, it would be wise to include a more diverse set of `native-country`. This would allow the model to better generalize and make accurate predictions for individuals from countries other than the United States.\n",
    "\n",
    "\n",
    "#### Experience Limitation\n",
    "Even though the mini-project did allow us the freedom to choose our datasets as well as the various techniques and models we can use, we are still constraint by time as well as our understanding of the various models due to our lack of industrial experience as such we are unable to tackle with more interesting topics of unsupervised and reinforcement learning types as those have more potential when it comes down to creating a model that is more unique and is able to solve the real world issue. \n",
    "\n",
    "Despite that we ultimately acquired plenty of experience and knowledge in the field of Artifical Intelligence and especially Data Science through performing EDA/FE and testing with the various models and ultimately gridsearching as a form of ease of access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c8a19",
   "metadata": {},
   "source": [
    "## Chapter 8. Reference\n",
    "\n",
    "- [1] https://www.data-to-viz.com/\n",
    "- [2] https://archive.ics.uci.edu/dataset/2/adult\n",
    "- [3] https://pbpython.com/categorical-encoding.html\n",
    "- [4] https://www.mygreatlearning.com/blog/gridsearchcv/\n",
    "- [5] https://www.geeksforgeeks.org/ml-gradient-boosting/\n",
    "- [6] https://seaborn.pydata.org/tutorial/color_palettes.html\n",
    "- [7] https://www.geeksforgeeks.org/what-is-feature-engineering/\n",
    "- [8] https://www.geeksforgeeks.org/data-visualization-in-jupyter-notebook/\n",
    "- [9] https://www.geeksforgeeks.org/data-visualization-with-python-seaborn/\n",
    "- [10] https://towardsdatascience.com/jupyter-notebook-best-practices-f430a6ba8c69\n",
    "- [11] https://coderpad.io/blog/data-science/mastering-jupyter-notebooks-best-practices-for-data-science/\n",
    "- [12] https://towardsdatascience.com/data-preprocessing-with-python-pandas-part-5-binning-c5bd5fd1b950\n",
    "- [13] https://www.ibm.com/docs/en/watson-studio-local/1.2.3?topic=notebooks-markdown-jupyter-cheatsheet\n",
    "- [14] https://www.analyticsvidhya.com/blog/2021/05/dealing-with-missing-values-in-python-a-complete-guide/\n",
    "- [15] https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9824d5b",
   "metadata": {},
   "source": [
    "### <center>End of Notebook</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6478c9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
